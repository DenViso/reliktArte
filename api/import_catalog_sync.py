import sys
import os
import time
import traceback
from pathlib import Path
from dotenv import load_dotenv
from collections import defaultdict
from sqlalchemy import create_engine, select, text
from sqlalchemy.orm import sessionmaker, Session

# –Ü–º–ø–æ—Ä—Ç –≤–∞—à–∏—Ö –º–æ–¥–µ–ª–µ–π —Ç–∞ –µ–Ω—É–º—ñ–≤
from src.product.models import (
    Product, Category, ProductPhoto, 
    ProductSize, ProductColor, ProductGlassColor
)
from src.product.enums import ProductPhotoDepEnum

# –°–ø—Ä–æ–±–∞ —ñ–º–ø–æ—Ä—Ç—É docx
try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False
    print("‚ö†Ô∏è python-docx –Ω–µ –≤—Å—Ç–∞–Ω–æ–≤–ª–µ–Ω–æ. –û–ø–∏—Å–∏ –Ω–µ –±—É–¥—É—Ç—å –∑—á–∏—Ç–∞–Ω—ñ.")

# –ì–ª–æ–±–∞–ª—å–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
STATS = {
    'catalog_analysis': {},
    'import_details': defaultdict(lambda: {
        'folders': 0, 'photos': 0, 'docs': 0,
        'products_added': 0, 'products_updated': 0, 'photos_added': 0
    })
}

# --- 1. –ü–Ü–î–ì–û–¢–û–í–ö–ê –ë–ê–ó–ò –î–ê–ù–ò–• ---

def sync_references(session: Session, category: Category):
    """–ì–∞—Ä–∞–Ω—Ç—É—î –Ω–∞—è–≤–Ω—ñ—Å—Ç—å –±–∞–∑–æ–≤–∏—Ö —Ä–æ–∑–º—ñ—Ä—ñ–≤ —Ç–∞ –∫–æ–ª—å–æ—Ä—ñ–≤ –¥–ª—è –∫–∞—Ç–µ–≥–æ—Ä—ñ—ó"""
    standard_sizes = [
        {"height": 2000, "width": 600, "thickness": 40},
        {"height": 2000, "width": 700, "thickness": 40},
        {"height": 2000, "width": 800, "thickness": 40},
        {"height": 2000, "width": 900, "thickness": 40},
    ]
    
    db_sizes = []
    for s in standard_sizes:
        size = session.query(ProductSize).filter_by(**s).first()
        if not size:
            size = ProductSize(**s)
            session.add(size)
            session.flush()
        db_sizes.append(size)
    
    category.allowed_sizes = db_sizes
    
    default_color = session.query(ProductColor).filter_by(name="–°—Ç–∞–Ω–¥–∞—Ä—Ç").first()
    if not default_color:
        default_color = ProductColor(name="–°—Ç–∞–Ω–¥–∞—Ä—Ç")
        session.add(default_color)
    
    session.flush()
    return db_sizes[0], default_color

# --- 2. –û–ë–†–û–ë–ö–ê –ö–û–ù–¢–ï–ù–¢–£ ---

def extract_docx_content(file_path):
    """–ó—á–∏—Ç—É—î —Ç–µ–∫—Å—Ç, –≤–∏–∑–Ω–∞—á–∞—î —Å–∫–ª–æ, –æ—Ä—ñ—î–Ω—Ç–∞—Ü—ñ—é —Ç–∞ –ø–æ–∫—Ä–∏—Ç—Ç—è"""
    if not DOCX_AVAILABLE or not file_path.exists():
        return "–û–ø–∏—Å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π", [{"value": "–û–ø–∏—Å –≤—ñ–¥—Å—É—Ç–Ω—ñ–π"}], None, False, False, None

    try:
        doc = Document(file_path)
        lines = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
        if not lines: 
            return "–û–ø–∏—Å –ø–æ—Ä–æ–∂–Ω—ñ–π", [{"value": "–û–ø–∏—Å –ø–æ—Ä–æ–∂–Ω—ñ–π"}], None, False, False, None

        details = [{"value": line} for line in lines]
        full_text = " ".join(lines).lower()
        
        # –í–∏–∑–Ω–∞—á–∞—î–º–æ –ø–æ–∫—Ä–∏—Ç—Ç—è
        covering = next((line for line in lines if any(kw in line.lower() for kw in ['–ø–≤—Ö', '—à–ø–æ–Ω', '–ª–∞–º—ñ–Ω–∞—Ç', '–¥—É–±'])), None)
        
        # --- –õ–û–ì–Ü–ö–ê –°–ö–õ–ê ---
        # –®—É–∫–∞—î–º–æ —Ä—è–¥–æ–∫ –ø—Ä–æ —Å–∫–ª–æ
        glass_line = next((line for line in lines if any(kw in line.lower() for kw in ['—Å–∫–ª–æ', '—Å–∫–ª—ñ–Ω–Ω—è', '–∑–∞—Å–∫–ª–µ–Ω–∞'])), None)
        
        has_glass = False
        glass_value = None
        
        if glass_line:
            if "–±–µ–∑ —Å–∫–ª–∞" in glass_line.lower():
                has_glass = False
                glass_value = None # –Ø–∫—â–æ "–ë–µ–∑ –°–∫–ª–∞" -> null
            else:
                has_glass = True
                glass_value = glass_line # –Ø–∫—â–æ –Ω–∞–∑–≤–∞ —Å–∫–ª–∞ —î -> –ø–µ—Ä–µ–¥–∞—î–º–æ –∑–Ω–∞—á–µ–Ω–Ω—è
        
        has_orient = any(kw in full_text for kw in ['–ø—Ä–∞–≤–µ', '–ª—ñ–≤–µ', '–ø—Ä–∞–≤–∏–π', '–ª—ñ–≤–∏–π'])
        
        # --- –§–û–†–ú–£–í–ê–ù–ù–Ø SUMMARY (–±–µ–∑ –ø–æ–∫—Ä–∏—Ç—Ç—è) ---
        # –ë–µ—Ä–µ–º–æ –ø–µ—Ä—à—ñ 2 —Ä—è–¥–∫–∏, —ñ–≥–Ω–æ—Ä—É—é—á–∏ —Ä—è–¥–æ–∫ –∑ –ø–æ–∫—Ä–∏—Ç—Ç—è–º
        summary_parts = []
        for line in lines[:2]:
            if covering and line == covering:
                continue
            summary_parts.append(line)
        summary = " ‚Ä¢ ".join(summary_parts)
        
        return summary, details, covering, has_glass, has_orient, glass_value
    except Exception:
        return "–ü–æ–º–∏–ª–∫–∞ —Ñ–∞–π–ª—É", [{"value": "–ü–æ–º–∏–ª–∫–∞ —á–∏—Ç–∞–Ω–Ω—è"}], None, False, False, None

# --- 3. –ê–ù–ê–õ–Ü–ó –¢–ê –Ü–ú–ü–û–†–¢ ---

def analyze_and_import(session: Session, cat_name: str):
    folder_key = "door" if cat_name == "–î–≤–µ—Ä—ñ" else "mouldings"
    base_path = Path(f"static/catalog/{folder_key}")
    
    if not base_path.exists():
        print(f"‚ùå –®–ª—è—Ö –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ: {base_path}")
        return

    cat = session.query(Category).filter_by(name=cat_name).first()
    if not cat:
        cat = Category(name=cat_name, is_glass_available=(cat_name == "–î–≤–µ—Ä—ñ"))
        session.add(cat)
        session.flush()
    
    def_size, def_color = sync_references(session, cat)

    print(f"\nüîç –ê–ù–ê–õ–Ü–ó –¢–ê –Ü–ú–ü–û–†–¢: {cat_name.upper()}")
    print("-" * 60)

    product_dirs = []
    if cat_name == "–î–≤–µ—Ä—ñ":
        for class_dir in sorted(base_path.iterdir()):
            if class_dir.is_dir():
                for p_dir in sorted(class_dir.iterdir()):
                    if p_dir.is_dir():
                        product_dirs.append((class_dir.name, p_dir))
    else:
        for p_dir in sorted(base_path.iterdir()):
            if p_dir.is_dir():
                product_dirs.append(("–ë–∞–∑–æ–≤–∞", p_dir))

    for class_name, p_dir in product_dirs:
        photos = list(p_dir.glob('*.webp')) + list(p_dir.glob('*.jpg')) + list(p_dir.glob('*.png'))
        if not photos and not (p_dir / "description.docx").exists():
            continue

        STATS['import_details'][cat_name]['folders'] += 1
        
        # –û—Ç—Ä–∏–º—É—î–º–æ –æ–Ω–æ–≤–ª–µ–Ω—ñ –¥–∞–Ω—ñ –∑ docx
        summary, details, cover, glass, orient, glass_v = extract_docx_content(p_dir / "description.docx")
        
        sku = f"{folder_key[:3]}-{class_name}-{p_dir.name}".upper().replace(' ', '-')
        product = session.query(Product).filter_by(sku=sku).first()

        desc_json = {"text": summary, "details": details}
        if cover: desc_json["finishing"] = {"covering": {"text": cover}}

        if not product:
            product = Product(
                sku=sku, category_id=cat.id, price=5000,
                name=f"{class_name} {p_dir.name}",
                description=desc_json,
                have_glass=glass, orientation_choice=orient
            )
            session.add(product)
            session.flush()
            STATS['import_details'][cat_name]['products_added'] += 1
            print(f"  ‚ûï –î–æ–¥–∞–Ω–æ: {sku}")
        else:
            product.description = desc_json
            product.have_glass = glass
            product.orientation_choice = orient
            STATS['import_details'][cat_name]['products_updated'] += 1
            print(f"  üîÑ –û–Ω–æ–≤–ª–µ–Ω–æ: {sku}")

        # –§–æ—Ç–æ
        existing_photos = {p.photo for p in session.query(ProductPhoto).filter_by(product_id=product.id).all()}
        for idx, p_file in enumerate(sorted(photos)):
            web_path = f"/static/catalog/{folder_key}/{p_dir.relative_to(base_path)}/{p_file.name}"
            if web_path not in existing_photos:
                new_photo = ProductPhoto(
                    photo=web_path, 
                    product_id=product.id,
                    is_main=(idx == 0),
                    dependency=ProductPhotoDepEnum.COLOR,
                    color_id=def_color.id, 
                    size_id=def_size.id,
                    with_glass=glass_v # –ó–∞–ø–∏—Å—É—î–º–æ –Ω–∞–∑–≤—É —Å–∫–ª–∞ –∞–±–æ None
                )
                session.add(new_photo)
                STATS['import_details'][cat_name]['photos_added'] += 1

# --- 4. –ó–ê–ü–£–°–ö ---

def main():
    load_dotenv('.env')
    db_url = os.getenv('DATABASE_URL')
    if not db_url:
        print("‚ùå –ü–æ–º–∏–ª–∫–∞: DATABASE_URL –Ω–µ –∑–Ω–∞–π–¥–µ–Ω–æ")
        return
    
    db_url = db_url.replace('postgresql://', 'postgresql+psycopg2://')
    engine = create_engine(db_url, pool_pre_ping=True)
    SessionLocal = sessionmaker(bind=engine)
    
    print("üöÄ –°–¢–ê–†–¢ –£–ù–Ü–í–ï–†–°–ê–õ–¨–ù–û–ì–û –Ü–ú–ü–û–†–¢–£ (V2)")
    print("=" * 60)
    
    with SessionLocal() as session:
        try:
            analyze_and_import(session, "–î–≤–µ—Ä—ñ")
            analyze_and_import(session, "–õ–∏—à—Ç–≤–∏")
            session.commit()
            
            print("\n" + "=" * 60)
            print("üìä –ü–Ü–î–°–£–ú–ö–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
            for cat, data in STATS['import_details'].items():
                print(f"üì¶ {cat}: {data['products_added']} –Ω–æ–≤–∏—Ö, {data['products_updated']} –æ–Ω–æ–≤–ª–µ–Ω–æ, {data['photos_added']} —Ñ–æ—Ç–æ")
            print("=" * 60)
            print("üéâ –í–°–ï –£–°–ü–Ü–®–ù–û –ó–ê–í–ï–†–®–ï–ù–û!")
            
        except Exception as e:
            session.rollback()
            print(f"\n‚ùå –ö–†–ò–¢–ò–ß–ù–ê –ü–û–ú–ò–õ–ö–ê: {e}")
            traceback.print_exc()

if __name__ == "__main__":
    main()