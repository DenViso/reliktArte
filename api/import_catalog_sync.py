import os
import traceback
from pathlib import Path
from dotenv import load_dotenv
from collections import defaultdict
from sqlalchemy import create_engine, text
from sqlalchemy.orm import sessionmaker, Session

# –Ü–º–ø–æ—Ä—Ç –≤–∞—à–∏—Ö –º–æ–¥–µ–ª–µ–π
from src.product.models import (
    Product, Category, ProductPhoto, 
    ProductSize, ProductColor
)
from src.product.enums import ProductPhotoDepEnum

try:
    from docx import Document
    DOCX_AVAILABLE = True
except ImportError:
    DOCX_AVAILABLE = False

# –†–æ–∑—à–∏—Ä–µ–Ω–∞ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞
STATS = {
    'total_deleted': 0,
    'import_details': defaultdict(lambda: {
        'added': 0, 
        'updated': 0, # –£ –ª–æ–≥—ñ—Ü—ñ TRUNCATE –±—É–¥–µ 0
        'photos': 0
    })
}

# --- 1. –û–ë–†–û–ë–ö–ê –ö–û–ù–¢–ï–ù–¢–£ ---
def extract_docx_content(file_path):
    if not DOCX_AVAILABLE or not file_path.exists():
        return "–ë–µ–∑ –æ–ø–∏—Å—É", [], None, False, False, None, "UNKNOWN"

    try:
        doc = Document(file_path)
        lines = [p.text.strip() for p in doc.paragraphs if p.text.strip()]
        if not lines: return "–ü–æ—Ä–æ–∂–Ω—å–æ", [], None, False, False, None, "EMPTY"

        details = [{"value": line} for line in lines]
        full_text = " ".join(lines).lower()
        
        extracted_sku = lines[0].strip()
        covering = next((line for line in lines if any(kw in line.lower() for kw in ['–ø–≤—Ö', '—à–ø–æ–Ω', '–ª–∞–º—ñ–Ω–∞—Ç', '–¥—É–±'])), None)
        
        glass_line = next((line for line in lines if any(kw in line.lower() for kw in ['—Å–∫–ª–æ', '—Å–∫–ª—ñ–Ω–Ω—è', '–∑–∞—Å–∫–ª–µ–Ω–∞'])), None)
        has_glass = False
        glass_value = None
        negation = ['–±–µ–∑', '–Ω–µ –º–∞—î', '–Ω–µ–º–∞—î', '–≤—ñ–¥—Å—É—Ç–Ω—î', '–≥–ª—É—Ö–∞']
        
        if glass_line:
            if not any(n in glass_line.lower() for n in negation):
                has_glass = True
                glass_value = glass_line
        elif '–≥–ª—É—Ö–∞' in full_text:
            has_glass = False

        has_orient = any(kw in full_text for kw in ['–ø—Ä–∞–≤–µ', '–ª—ñ–≤–µ', '–ø—Ä–∞–≤–∏–π', '–ª—ñ–≤–∏–π'])
        
        stop_keywords = ['–ø–≤—Ö', '—à–ø–æ–Ω', '–ª–∞–º—ñ–Ω–∞—Ç', '–¥—É–±', '2000', '—Ö', '—Å–∫–ª–∞', '—Å–∫–ª–æ']
        clean_parts = []
        for line in lines[:3]:
            if covering and line == covering: continue
            if any(s in line.lower() for s in stop_keywords): continue
            clean_parts.append(line)
            if len(clean_parts) >= 2: break
        summary = " ‚Ä¢ ".join(clean_parts)
        
        return summary, details, covering, has_glass, has_orient, glass_value, extracted_sku
    except:
        return "–ü–æ–º–∏–ª–∫–∞", [], None, False, False, None, "ERROR"

# --- 2. –°–ò–ù–•–†–û–ù–Ü–ó–ê–¶–Ü–Ø –î–û–í–Ü–î–ù–ò–ö–Ü–í ---
def sync_refs(session: Session, category: Category):
    def_size = session.query(ProductSize).first()
    if not def_size:
        def_size = ProductSize(height=2000, width=800, thickness=40)
        session.add(def_size); session.flush()
    
    def_color = session.query(ProductColor).filter_by(name="–°—Ç–∞–Ω–¥–∞—Ä—Ç").first()
    if not def_color:
        def_color = ProductColor(name="–°—Ç–∞–Ω–¥–∞—Ä—Ç")
        session.add(def_color); session.flush()
    
    return def_size, def_color

# --- 3. –û–°–ù–û–í–ù–ò–ô –Ü–ú–ü–û–†–¢ ---
def analyze_and_import(session: Session, cat_name: str):
    folder_key = "door" if cat_name == "–î–≤–µ—Ä—ñ" else "mouldings"
    base_path = Path(f"static/catalog/{folder_key}")
    if not base_path.exists(): return

    cat = session.query(Category).filter_by(name=cat_name).first()
    if not cat:
        cat = Category(name=cat_name, is_glass_available=(cat_name=="–î–≤–µ—Ä—ñ"))
        session.add(cat); session.flush()
    
    def_size, def_color = sync_refs(session, cat)

    product_dirs = []
    if cat_name == "–î–≤–µ—Ä—ñ":
        for class_dir in sorted(base_path.iterdir()):
            if class_dir.is_dir():
                for p_dir in sorted(class_dir.iterdir()):
                    if p_dir.is_dir(): product_dirs.append((class_dir.name, p_dir))
    else:
        for p_dir in sorted(base_path.iterdir()):
            if p_dir.is_dir(): product_dirs.append(("–ë–∞–∑–æ–≤–∞", p_dir))

    for class_name, p_dir in product_dirs:
        photos = list(p_dir.glob('*.webp'))
        summary, details, cover, glass, orient, g_val, sku = extract_docx_content(p_dir / "description.docx")
        
        desc_json = {"text": summary, "details": details}
        if cover: desc_json["finishing"] = {"covering": {"text": cover}}

        product = Product(
            sku=sku, category_id=cat.id, price=0, 
            name=f"{class_name} {p_dir.name}",
            description=desc_json,
            have_glass=glass, orientation_choice=orient
        )
        session.add(product); session.flush()
        STATS['import_details'][cat_name]['added'] += 1

        for idx, p_file in enumerate(sorted(photos)):
            web_path = f"/static/catalog/{folder_key}/{p_dir.relative_to(base_path)}/{p_file.name}"
            new_photo = ProductPhoto(
                photo=web_path, product_id=product.id, is_main=(idx == 0),
                dependency=ProductPhotoDepEnum.COLOR,
                color_id=def_color.id, size_id=def_size.id, with_glass=g_val
            )
            session.add(new_photo)
            STATS['import_details'][cat_name]['photos'] += 1

# --- 4. –ó–ê–ü–£–°–ö –¢–ê –û–ß–ò–©–ï–ù–ù–Ø ---
def main():
    load_dotenv('.env')
    db_url = os.getenv('DATABASE_URL').replace('postgresql://', 'postgresql+psycopg2://')
    engine = create_engine(db_url)
    SessionLocal = sessionmaker(bind=engine)
    
    with SessionLocal() as session:
        try:
            print("üî¥ –ö—Ä–æ–∫ 1: –ê–Ω–∞–ª—ñ–∑ —Ç–∞ –æ—á–∏—â–µ–Ω–Ω—è –±–∞–∑–∏...")
            
            # –†–∞—Ö—É—î–º–æ —Å–∫—ñ–ª—å–∫–∏ –±—É–ª–æ –ø–µ—Ä–µ–¥ –≤–∏–¥–∞–ª–µ–Ω–Ω—è–º
            old_count = session.query(Product).count()
            STATS['total_deleted'] = old_count
            
            # –ü–æ–≤–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è
            session.execute(text("TRUNCATE TABLE products RESTART IDENTITY CASCADE"))
            print(f"‚úÖ –í–∏–¥–∞–ª–µ–Ω–æ –∑–∞–ø–∏—Å—ñ–≤: {old_count}")

            print("üü¢ –ö—Ä–æ–∫ 2: –ó–∞–ø–∏—Å –Ω–æ–≤–∏—Ö –¥–∞–Ω–∏—Ö...")
            analyze_and_import(session, "–î–≤–µ—Ä—ñ")
            analyze_and_import(session, "–õ–∏—à—Ç–≤–∏")
            
            session.commit()
            
            print("\n" + "‚ïê"*50)
            print("üìä –ü–Ü–î–°–£–ú–ö–û–í–ê –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
            print("‚îÄ"*50)
            print(f"üóëÔ∏è  –í–°–¨–û–ì–û –í–ò–î–ê–õ–ï–ù–û –°–¢–ê–†–ò–• –¢–û–í–ê–†–Ü–í: {STATS['total_deleted']}")
            print(f"üîÑ –í–°–¨–û–ì–û –û–ù–û–í–õ–ï–ù–û (–ø–µ—Ä–µ–∑–∞–ø–∏—Å–∞–Ω–æ): 0 (–æ–±—Ä–∞–Ω–æ –ø–æ–≤–Ω–µ –æ—á–∏—â–µ–Ω–Ω—è)")
            print("‚îÄ"*50)
            
            total_added = 0
            for cat, d in STATS['import_details'].items():
                print(f"üì¶ {cat}: –ó–∞–ø–∏—Å–∞–Ω–æ {d['added']} —à—Ç. (+ {d['photos']} —Ñ–æ—Ç–æ)")
                total_added += d['added']
            
            print("‚îÄ"*50)
            print(f"‚ú® –†–ï–ó–£–õ–¨–¢–ê–¢: +{total_added} –Ω–æ–≤–∏—Ö –∑–∞–ø–∏—Å—ñ–≤ —É –±–∞–∑—ñ")
            print("‚ïê"*50)
            print("üéâ –ö–ê–¢–ê–õ–û–ì –ü–û–í–ù–Ü–°–¢–Æ –û–ù–û–í–õ–ï–ù–û!")

        except Exception as e:
            session.rollback()
            print(f"‚ùå –ü–æ–º–∏–ª–∫–∞: {e}")
            traceback.print_exc()

if __name__ == "__main__":
    main()